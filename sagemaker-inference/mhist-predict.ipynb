{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a1692c-cfa0-4bf1-bbd6-f607e54d3746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/histology-image-analysis/sagemaker-inference\n",
      "MHIST_ViT_v13_dynamo_model.onnx  mhist-predict.ipynb  test_locally.py\n",
      "__pycache__\t\t\t model.tar.gz\n",
      "example_inference.py\t\t src\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls\n",
    "\n",
    "# SageMaker Studio Code Editor working directory:\n",
    "# /home/sagemaker-user/histology-image-analysis/sagemaker-inference\n",
    "\n",
    "# SageMaker Notebook Instance working directory:\n",
    "# /home/ec2-user/SageMaker/histology-image-analysis/sagemaker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b4d40",
   "metadata": {},
   "source": [
    "SageMaker recommends the structure:\n",
    "```\n",
    "model.tar.gz/\n",
    "|- model.pth\n",
    "|- src/\n",
    "  |- inference.py\n",
    "  |- requirements.txt  # only for versions 1.3.1 and higher\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb50747d-3c7a-417a-a8cb-9a250d4e0056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_type application/json\n",
      "Output: ('{\"logit\": 3.948834180831909, \"predicted_class\": \"SSA\", \"probability\": 0.9810874185378591}', 'application/json')\n"
     ]
    }
   ],
   "source": [
    "# Test inference locally\n",
    "!pip install -U -q -r src/requirements.txt\n",
    "%run test_locally.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923236bc-9840-4f39-b510-5628992f15f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHIST_ViT_v13_dynamo_model.onnx\n",
      "src/\n",
      "src/inference.py\n",
      "src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Compress\n",
    "# -c create archive\n",
    "# -z gzip\n",
    "# -v verbose\n",
    "# -f to filename\n",
    "!tar -czvf model.tar.gz MHIST_ViT_v13_dynamo_model.onnx src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d0a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHIST_ViT_v13_dynamo_model.onnx\n",
      "src/\n",
      "src/inference.py\n",
      "src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Uncompress\n",
    "# -x extract\n",
    "# -z gzip\n",
    "# -v verbose\n",
    "# -f from filename\n",
    "!tar -xzvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d69bc79-b266-4c53-8230-be6f40fb2892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Model files uploaded to: s3://sagemaker-us-west-1-851725529671/mhist-vit-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Upload model files to SageMaker default bucket\n",
    "# !pip install -U sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "dest = sagemaker_session.upload_data(path='model.tar.gz', bucket=bucket, key_prefix='mhist-vit-model')\n",
    "\n",
    "print(f\"Model files uploaded to: {dest}\")\n",
    "# Model files uploaded to: s3://sagemaker-us-west-1-851725529671/mhist-vit-model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee153ca",
   "metadata": {},
   "source": [
    "Deploy a pretrained PyTorch model:\n",
    "- create a PyTorchModel object and set an entry_point\n",
    "- deploy a PyTorchPredictor\n",
    "\n",
    "This creates a SageMaker Endpoint -- a hosted prediction service that we can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac6845f-d785-4339-8c8a-00261f2be6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logit': 3.948834180831909,\n",
       " 'predicted_class': 'SSA',\n",
       " 'probability': 0.9810874185378591}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a PyTorch Endpoint from SageMaker Python SDK's PyTorch Model\n",
    "# to deploy a PyTorch model trained outside of SageMaker.\n",
    "# The AWS Model server is natively integrated with TorchServe,\n",
    "# an open-source project developed by AWS and Facebook to serve PyTorch models.\n",
    "\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role() # arn:aws:iam::851725529671:role/SageMakerEx\n",
    "model_data = 's3://sagemaker-us-west-1-851725529671/mhist-vit-model/model.tar.gz'\n",
    "\n",
    "# Configure the SageMaker PyTorch model server\n",
    "model = PyTorchModel(\n",
    "    # Model params\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    source_dir='src',\n",
    "    entry_point='inference.py',\n",
    "\n",
    "    # PyTorchModel params\n",
    "    framework_version='2.3.0',\n",
    "    py_version='py311',\n",
    "    dependencies=['src/requirements.txt']\n",
    ")\n",
    "# deploy() creates a SageMaker Endpoint, a hosted prediction service\n",
    "# returns a PyTorchPredictor, which runs inference on PyTorch Endpoints\n",
    "# with the (above) PyTorch model server.\n",
    "# Predictor will serialize Python lists, dictionaries, and numpy arrays\n",
    "# to multidimensional tensors for PyTorch inference.\n",
    "predictor = model.deploy(\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(), # Default serializes input data to .npy format\n",
    "    deserializer=JSONDeserializer() # Default parses the response from .npy format to numpy array.\n",
    ")\n",
    "# Test Endpoint \n",
    "response = predictor.predict({\n",
    "    'bucket': 'mhist-streamlit-app',\n",
    "    'key': 'images/original/MHIST_aah.png'\n",
    "})\n",
    "\n",
    "# Expected output:\n",
    "# {\"logit\": 3.948834180831909,\n",
    "# \"predicted_class\": \"SSA\",\n",
    "# \"probability\": 0.9810874185378591}\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433f4dbf-26a0-455b-a5e8-ac8901070baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
