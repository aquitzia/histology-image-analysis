{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bdc037",
   "metadata": {},
   "source": [
    "# **Deploy a pretrained, optimized ONNX model to SageMaker Endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git doesn't work well within the AWS Studio Code Editor space\n",
    "# Make sure the code is up-to-date:\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a1692c-cfa0-4bf1-bbd6-f607e54d3746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/histology-image-analysis/sagemaker-inference\n",
      "MHIST_ViT_v13_dynamo_model.onnx  mhist-predict.ipynb  test_locally.py\n",
      "__pycache__\t\t\t model.tar.gz\n",
      "example_inference.py\t\t src\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls\n",
    "\n",
    "# SageMaker Studio Code Editor working directory:\n",
    "# /home/sagemaker-user/histology-image-analysis/sagemaker-inference\n",
    "\n",
    "# SageMaker Notebook Instance working directory:\n",
    "# /home/ec2-user/SageMaker/histology-image-analysis/sagemaker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17726b8",
   "metadata": {},
   "source": [
    "### Upload model artifacts to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b4d40",
   "metadata": {},
   "source": [
    "SageMaker recommends the structure:\n",
    "```\n",
    "model.tar.gz/\n",
    "|- model.pth\n",
    "|- src/\n",
    "  |- inference.py\n",
    "  |- requirements.txt  # only for versions 1.3.1 and higher\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb50747d-3c7a-417a-a8cb-9a250d4e0056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_type application/json\n",
      "Output: ('{\"logit\": 3.948834180831909, \"predicted_class\": \"SSA\", \"probability\": 0.9810874185378591}', 'application/json')\n"
     ]
    }
   ],
   "source": [
    "# Test inference locally\n",
    "!pip install -U -q -r src/requirements.txt\n",
    "%run test_locally.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923236bc-9840-4f39-b510-5628992f15f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHIST_ViT_v13_dynamo_model.onnx\n",
      "src/\n",
      "src/inference.py\n",
      "src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Compress\n",
    "# -c create archive\n",
    "# -z gzip\n",
    "# -v verbose\n",
    "# -f to filename\n",
    "!tar -czvf model.tar.gz MHIST_ViT_v13_dynamo_model.onnx src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d0a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHIST_ViT_v13_dynamo_model.onnx\n",
      "src/\n",
      "src/inference.py\n",
      "src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Uncompress\n",
    "# -x extract\n",
    "# -z gzip\n",
    "# -v verbose\n",
    "# -f from filename\n",
    "!tar -xzvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d69bc79-b266-4c53-8230-be6f40fb2892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Model files uploaded to: s3://sagemaker-us-west-1-851725529671/mhist-vit-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Upload model files to SageMaker default bucket\n",
    "# !pip install -U sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "S3_FILENAME = 'model.tar.gz'\n",
    "S3_PREFIX = 'mhist-vit'\n",
    "\n",
    "# Upload the model artifacts to S3\n",
    "model_path = sagemaker_session.upload_data(\n",
    "    path=S3_FILENAME,\n",
    "    bucket=bucket,\n",
    "    key_prefix=S3_PREFIX)\n",
    "\n",
    "print(f\"Model files uploaded to: {model_path}\")\n",
    "# Model files uploaded to: s3://sagemaker-us-west-1-851725529671/mhist-vit-model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd3bfa",
   "metadata": {},
   "source": [
    "The output message states that SageMaker SDK is using its built-in default settings rather than any custom configurations, located at:\n",
    "- `/etc/xdg/sagemaker/config.yaml`: system-wide config\n",
    "- `/home/sagemaker-user/.config/sagemaker/config.yaml`: user-specific config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee153ca",
   "metadata": {},
   "source": [
    "### Deploy PyTorchModel server and PyTorchPredictor Endpoint:\n",
    "- create a PyTorchModel object and set an entry_point\n",
    "- deploy a PyTorchPredictor\n",
    "\n",
    "This creates a SageMaker Endpoint -- a hosted prediction service that we can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac6845f-d785-4339-8c8a-00261f2be6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logit': 3.948834180831909,\n",
       " 'predicted_class': 'SSA',\n",
       " 'probability': 0.9810874185378591}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a PyTorch Endpoint from SageMaker Python SDK's PyTorch Model\n",
    "# to deploy a PyTorch model trained outside of SageMaker.\n",
    "# The AWS Model server is natively integrated with TorchServe,\n",
    "# an open-source project developed by AWS and Facebook to serve PyTorch models.\n",
    "\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role() # arn:aws:iam::851725529671:role/SageMakerEx\n",
    "# model_path = 's3://sagemaker-us-west-1-851725529671/mhist-vit/model.tar.gz'\n",
    "\n",
    "# Configure the SageMaker PyTorch model server\n",
    "model = PyTorchModel(\n",
    "    # Model params\n",
    "    model_data=model_path,\n",
    "    role=role,\n",
    "    source_dir='src',\n",
    "    entry_point='inference.py',\n",
    "\n",
    "    # PyTorchModel params\n",
    "    framework_version='2.3.0',\n",
    "    py_version='py311',\n",
    "    dependencies=['src/requirements.txt']\n",
    ")\n",
    "print(f\"Created PyTorchModel: {model.model_name}\")\n",
    "\n",
    "# deploy() creates a SageMaker Endpoint, a hosted prediction service\n",
    "# returns a PyTorchPredictor, which runs inference on PyTorch Endpoints\n",
    "# with the (above) PyTorch model server.\n",
    "# Predictor will serialize Python lists, dictionaries, and numpy arrays\n",
    "# to multidimensional tensors for PyTorch inference.\n",
    "predictor = model.deploy(\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(), # Default serializes input data to .npy format\n",
    "    deserializer=JSONDeserializer() # Default parses the response from .npy format to numpy array.\n",
    ")\n",
    "print(f\"Created PyTorchPredictor Endpoint: {predictor.endpoint_name}\")\n",
    "\n",
    "# Test Endpoint \n",
    "response = predictor.predict({\n",
    "    'bucket': 'mhist-streamlit-app',\n",
    "    'key': 'images/original/MHIST_aah.png'\n",
    "})\n",
    "\n",
    "# Expected output:\n",
    "# {\"logit\": 3.948834180831909,\n",
    "# \"predicted_class\": \"SSA\",\n",
    "# \"probability\": 0.9810874185378591}\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10bee1",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28798c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SageMaker Endpoint, which incurs significant fees to run\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "# List model artifacts in S3\n",
    "objects = s3.list_objects_v2(Bucket=bucket)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433f4dbf-26a0-455b-a5e8-ac8901070baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally delete the SageMaker model, which doesn't incur charges\n",
    "# (or go to SageMaker Studio --> Models --> Deployable Models)\n",
    "model.delete_model()\n",
    "\n",
    "# Delete model artifacts from sagemaker.Session().default_bucket()\n",
    "S3_FILENAME = 'model.tar.gz'\n",
    "S3_PREFIX = 'mhist-vit'\n",
    "s3.delete_object(Bucket=bucket, Key=f\"{S3_FILENAME}/{S3_PREFIX}\")\n",
    "\n",
    "objects = s3.list_objects_v2(Bucket=bucket)\n",
    "for obj in objects.get('Contents', []):\n",
    "    s3.delete_object(Bucket=bucket, Key=obj['Key'])\n",
    "\n",
    "# sagemaker.Session() object doesn't use any other resources (besides notebook memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbdad27",
   "metadata": {},
   "source": [
    "Also, remember to stop the Studio Instance:\n",
    "- Close this notebook, then click **SageMaker Studio --> Running Instances --> Stop**\n",
    "- When you stop the Studio instance, SageMaker with delete the associated EBS volume\n",
    "\n",
    "To double-check, go to the EC2 console\n",
    "- In the left sidebar, click Elastic Block Store --> Volumes\n",
    "- Look for any volumes with a name starting with \"sagemaker-\"\n",
    "\n",
    "Check **AWS Billing** dashboard to check for any resources that might be used accidentally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
